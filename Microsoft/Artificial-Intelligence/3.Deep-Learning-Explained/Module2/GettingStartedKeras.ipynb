{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Explained\n",
    "\n",
    "# Module 2 - Lab - Introduction to Keras \n",
    "\n",
    "# 1.0 Getting started with Keras\n",
    "\n",
    "This notebook will provide a first look at using the Keras package to define, train and evaluate deep learning models with Keras. By the end of this lesson you will be able to work with basic feedforward architecture multi-layer neural nets. Feedforward networks are one of a class of basic models called **sequential models** which are easy to define with Keras. Further, some basic regularization is introduced. Additional regularization methods are covered in a subsequent lesson. \n",
    "\n",
    "The details of feedforward models and regularization will be introduced in other lessons. For now, focus on becoming comfortable with using Keras so you are prepared for the rest of the labs in this course. \n",
    "\n",
    "****\n",
    "**Note:** This notebook was constructed and tested using Anaconda 3 with Python 3.7. It is assumed that the standard Anaconda stack has been installed.\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Keras architecture\n",
    "\n",
    "Keras is a wrapper over other deep learning frameworks. Keras provides consistent and simplified APIs for using these underlying frameworks. In this lesson we will focus on the widely used Python API. \n",
    "\n",
    "Presently, Keras supports TensorFlow, CNTK and Theano. For the labs for this course, we will be using Keras as a wrapper on top of TensorFlow.\n",
    "\n",
    "If you have not yet installed Keras and TensorFlow, follow the [installation instructions from the Keras site](https://keras.io/#installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Overview of Keras documentation\n",
    "\n",
    "One of the many nice features of Keras is complete and useful documentation. Complete documentation including installation instructions can be found on the [Keras website](https://keras.io/#keras-the-python-deep-learning-library). As you learn to work with Keras, you will want to refer to the well-indexed documentation and examples on this site. \n",
    "\n",
    "The book [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by Fran√ßois Chollet, the creator of Keras, provides in-depth examples and discussion on a wide range of deep learning applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 A first feed-forward Keras example\n",
    "\n",
    "Without further adu, let's try an example. We will build a simple feedforward neural network to classify handwritten digits from the famous MNIST data set. MNIST contains 60,000 labeled training images and 10,000 test images. Many people consider the MNIST dataset as the 'hello world' problem of deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading the MNIST data set\n",
    "\n",
    "MNIST is built in too the `keras.datasets` package. We only need to import this package and then load it. \n",
    "\n",
    "The first step is to import the packages we will need for the rest of this notebook. Execute the code in the cell below to load these packages. This code should execute without errors or warnings if everything is installed correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import keras.utils.np_utils as ku\n",
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "from keras import regularizers\n",
    "from keras.optimizers import rmsprop\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from tensorflow import set_random_seed\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the TensorFlow backend has been loaded along with various Keras packages. Keras is making calls to TensorFlow to perform compuations.\n",
    "\n",
    "Now, load the training and testing images and corresponding labels by executing the coded in the cell below. The `load_data` method creates two tuples of the images and labels for training and testing models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded, let's have a peak at some of the content. The images of the handwritten digits are represented as rectangular arrays of dimension $28x28$. You can see this by executing the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images[4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The handwritten images are all gray-scale, so do not have a color dimension. \n",
    "\n",
    "The code in the cell below displays 4 of the 60,000 images of handwritten digits along with their labels. Execute this code and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 20, 4):\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    print('Label = ' + str(train_labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prepare the data for training.\n",
    "\n",
    "As is the case with all machine learning problems, preparing the data is an important step. Without careful data preparation even the best models will produce poor results, or even fail to execute. \n",
    "\n",
    "The MNIST images are stored as a 3-d tensor. Each image tensor has dimensions $6000\\ x\\ 28\\ x\\ 28$. However, to train a neural network on these images we must flatten this representation so that each image is a vector of length $28 * 28$. The result will be a 2-d tensor of dimensions $60000\\ x\\ (28*28)$.\n",
    "\n",
    "Further, models created with Keras, and most other deep learning frameworks, operate on floating point numbers. The gray scale pixel values of the images are coded as integers in the range $\\{ 0, 255 \\}$. These pixel values must be coerced to floating point and then standardized to be in a range $\\{ 0.0, 1.0 \\}$. As is the case for training many machine learning models, it is best to use standardized values for training deep neural networks. \n",
    "\n",
    "The code in the cell below flattens the images and converts the pixel values to a standardized floating point number. Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_images.shape, train_labels.shape)\n",
    "train_images = train_images.reshape((60000, 28*28)).astype('float32')/255\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the original shape and resulting shape of the training image tensor. In addition, the array is now of type `float32`. \n",
    "\n",
    "Execute the code in the cell below to apply the  same transformation to the test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_images.shape, test_labels.shape)\n",
    "test_images = test_images.reshape((10000, 28*28)).astype('float32')/255\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working on a classification problem, the label values must be of a categorical type. Execute the code in the cell below and examine the coding of  these labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_labels[5:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are coded as integers corresponding to the digit in the image. These values must be coerced to a categorical type. For Keras, categorical types must be **one hot encoded**. One hot encoding is a set of binary columns, one for each category.       \n",
    "\n",
    "Fortunately the `to_categorical` method in the `keras.utils.np_utils` package does just this. Execute the code in the cell below and examine the printed results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = ku.to_categorical(train_labels)\n",
    "print(train_labels[5:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the label values have been converted from integers to a set of **10 dummy variables** of the one hot encoding. The columns of the dummy variables represent digits in the range $\\{ 0,9 \\}$. One dummy variable per case will be coded as $1$ and the rest coded as $0$. For example the first row in the example above encodes a $2$, and the second row encodes a $1$.\n",
    "\n",
    "Execute the code in the cell below to coerce the test labels to dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = ku.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Defining a sequential model\n",
    "\n",
    "The data is prepared, so it is time to start defining a neural nework model. We are using a simple feedforward model which is one type of sequential model Keras can create. There is a general receipe for defining sequential Keras models:\n",
    "\n",
    "1. Define a sequential model object.\n",
    "2. Define one or more hidden layers.\n",
    "3. Define an output layer. \n",
    "\n",
    "You will find a [quick start guide to Keras sequential models](https://keras.io/getting-started/sequential-model-guide/) in the Keras documentation \n",
    "\n",
    "Speficially in this case, the squential model is defined as follows:\n",
    "1. A sequential model object `nn` is defined. \n",
    "2. A single hidden layer is defined. \n",
    "  - This layer is dense (fully connected) with 512 units. \n",
    "  - The activation of each unit is rectilinear.\n",
    "  - The hidden layer is expecting an input tensor of $28*28$ by an undefined number of cases (images). \n",
    "3. The output layer has 10 hidden units. \n",
    "  - We need 10 units since there are 10 categories of handwritten digits we are classifing. \n",
    "  - This is a **Multinomial** classification problem so we are using softmax activation. \n",
    "  \n",
    "Execute this code to define the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, )))\n",
    "nn.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Training and evaluating the sequential model\n",
    "\n",
    "With a defined model it is time to train and evaluate it. First, the model must be compiled by executing the code below. This call specifies the following:\n",
    "\n",
    "1. Specify an optimizer. \n",
    "2. Specify a loss function. In this case we are performing Multinomial classification so we are using `categorical_crossentropy`.\n",
    "3. Specify one or more metrics used to evaluate the performance of the model. In this case we are using just one metric, accuracy. \n",
    "\n",
    "We will discuss the technical details of the model in subsequent lessons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the model is ready to be trained using the `fit` method by executing the code in the cell below. The `fit` method has several arguments:\n",
    "\n",
    "1. The training features.\n",
    "2. The training labels.\n",
    "3. The number of epochs (iterations) over which the model is trained.\n",
    "4. The batch size used for the optimizer. The meaning of this will be discussed in the lesson on optimizaton. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nr.seed(9898)\n",
    "set_random_seed(9777)\n",
    "nn.fit(train_images, train_labels, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the loss declines and the accuracy increases with each training epoch. However, since neural networks tend to be over-fit, these improved figures may or may not indicate that the model is actually getting better. Keep in mind that the model may simply be learning the training data. \n",
    "\n",
    "It is necessary to test the model on independent data set. The `evaluate` method allows you to do just this. Execute the code in the cell below and compare the results to training results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the model is over-fit since the evaluation loss and accuracy are a bit worse than observed in training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Training over epochs\n",
    "\n",
    "In order to determine at what point a model is overfit during training it is necessary to evaluate the model after each training epoch. A `history` object is created which contains the history of various metrics during the training or fitting process. \n",
    "\n",
    "Notice that the `validation_data` argument must be specified so that performance of the model can be computed at the end or each epoch. The printed history of the training will include the validation loss and validation accuracy for each epoch. \n",
    "\n",
    "Expect execution of this code to take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a sequential model and print a summary\n",
    "nnt = models.Sequential()\n",
    "nnt.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, )))\n",
    "nnt.add(layers.Dense(10, activation = 'softmax'))\n",
    "nnt.summary()\n",
    "\n",
    "## Compile the model. \n",
    "nnt.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', \n",
    "                metrics = ['accuracy'])\n",
    " \n",
    "## Fit the model saving the results to a history file    \n",
    "nr.seed(4678)\n",
    "set_random_seed(8866)\n",
    "history = nnt.fit(train_images, train_labels, \n",
    "                  epochs = 10, batch_size = 128,\n",
    "                  validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aid in understanding these figures it will help to make some plots comparing the training and evaluation performance as the training epochs evolve. The code in the next two cells does this is a somewhat primitive manner. The Numpy array is manually edited to include the training loss and training accuracy. \n",
    "\n",
    "The `plot_loss` and `plot_accuracy` functions, in the next two cell, plot the training loss or accuracy in blue and the test loss or accuracy in red. Execute the code and examine the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    train_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    x = list(range(1, len(test_loss) + 1))\n",
    "    plt.plot(x, test_loss, color = 'red', label = 'test loss')\n",
    "    plt.plot(x, train_loss, label = 'traning loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs. Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_loss(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    train_acc = history.history['acc']\n",
    "    test_acc = history.history['val_acc']\n",
    "    x = list(range(1, len(test_acc) + 1))\n",
    "    plt.plot(x, test_acc, color = 'red', label = 'test accuracy')\n",
    "    plt.plot(x, train_acc, label = 'training accuracy')  \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs. Epoch')  \n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "plot_accuracy(history)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training loss and accuracy continue to improve throughout the epochs. However, the evaluation loss and accuracy only improve significantly for the first four, or perhaps 5, epochs. This is clear evidence that subsequent epochs are simply over-fitting the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Adding hidden layers\n",
    "\n",
    "Next, we will add an additional hidden layer to the model. Additional layers add capacity to the model to represent complex function. However, the network becomes more susceptible to over fitting. Details of model capacity are discussed in other lessons.  \n",
    "\n",
    "The code in the cell below defines a model similar to the first one, but with a second layer defined. Notice that the definition of the two layer model is nearly the same as for the single layer model. In this case, the second layer has the same number of units and activation function as the first. \n",
    "\n",
    "However, notice that the `input_shape` does not need to be defined for hidden layers past the first. Keras will determine the dimensions of tensors passed between layers beyond the input. \n",
    "\n",
    "Expect execution of this code to take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a sequential model\n",
    "nnt = models.Sequential()\n",
    "nnt.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, )))\n",
    "nnt.add(layers.Dense(512, activation = 'relu'))\n",
    "nnt.add(layers.Dense(10, activation = 'softmax'))\n",
    "nnt.summary()\n",
    "\n",
    "## Compile the model\n",
    "nnt.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', \n",
    "                metrics = ['accuracy'])\n",
    "    \n",
    "## Fit the model, saving the results to a history file.     \n",
    "nr.seed(2432)\n",
    "set_random_seed(5544)\n",
    "history = nnt.fit(train_images, train_labels, \n",
    "                  epochs = 20, batch_size = 128,\n",
    "                  validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can best understand these results by creating plots of the loss and accuracy for training and evaluation vs. epoch. Execute the code in the two cells below to display these plots and study the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that after epoch four the true (training) loss actually increases, whereas the training loss continues to decrease. This is a clear indication of overfitting. \n",
    "\n",
    "When compared to the single layer example, the over-fitting is more obvious. This should not be a suprise, since the number of weights has nearly doubled from the single layer model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Adding regularization to the model\n",
    "\n",
    "Regularization is used to prevent over-fitting of machine learning models including neural networks. The Keras `regularizers` package provides L1 and L2 regularization methods. The theory of regularization will be addressed in other lessons. In addition you can find [documentation on the Keras `regularizers` package](https://keras.io/regularizers/).  \n",
    "\n",
    "The code in the cell below adds the `kernel_regularizer` argument with the value of `regularizers.l2(0.01)` This adds a weight decay penalty of 0.01 to the model weights. \n",
    "\n",
    "Execute the code. Expect execution to take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Difine the layers of the sequential model and print a summary\n",
    "nnt = models.Sequential()\n",
    "nnt.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, ),\n",
    "                        kernel_regularizer=regularizers.l2(0.001)))\n",
    "nnt.add(layers.Dense(512, activation = 'relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "nnt.add(layers.Dense(10, activation = 'softmax'))\n",
    "nnt.summary()\n",
    "\n",
    "## Define an optimzer object and compile the model\n",
    "optimizer = rmsprop()\n",
    "nnt.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "## Fit the compiled model    \n",
    "nr.seed(8765)\n",
    "set_random_seed(7654)\n",
    "history = nnt.fit(train_images, train_labels, \n",
    "                  epochs = 20, batch_size = 128,\n",
    "                  validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can best understand these results by creating plots of the loss and accuracy for training and evaluation vs. epoch. Execute the code in the two cells below to display these plots and study the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_loss(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to the previous un-regularized model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
